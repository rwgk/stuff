# Mostly generated by ChatGPT 2025-02-14+1100
# The only manual change is the `f.write(response.text)` part.

import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin

# Base URL
base_url = "https://github.com/NVIDIA/cuda-python/releases"

# Headers to mimic a browser request
headers = {"User-Agent": "Mozilla/5.0"}

page_counter = 0

def get_links_from_page(url):
    """Fetch all links from a GitHub releases page."""
    try:
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
    except requests.RequestException as e:
        print(f"Failed to fetch {url}: {e}")
        return [], None

    global page_counter
    page_counter += 1
    resp_txt = f"response_{page_counter}.txt"
    print(f"Writing: {resp_txt}")
    with open(resp_txt, "w") as f:
        f.write(response.text)
    soup = BeautifulSoup(response.text, "html.parser")

    # Extract all links on the page
    links = set(urljoin(url, a["href"]) for a in soup.find_all("a", href=True))

    # Find the "Next" button (if available)
    next_page = soup.find("a", class_="next_page")
    next_page_url = urljoin(url, next_page["href"]) if next_page else None

    return links, next_page_url

def check_link(url):
    """Check if a link is dead."""
    try:
        response = requests.head(url, headers=headers, allow_redirects=True, timeout=10)
        return response.status_code, response.url  # Follow redirects
    except requests.RequestException:
        return None, url  # Dead link

def main():
    page_url = base_url
    all_links = set()

    # Traverse all pages
    while page_url:
        print(f"Fetching links from: {page_url}")
        links, next_page = get_links_from_page(page_url)
        all_links.update(links)
        page_url = next_page  # Move to next page (if exists)

    print(f"\nTotal unique links found: {len(all_links)}. Checking them now...\n")

    dead_links = []
    for link in all_links:
        status, final_url = check_link(link)
        if status is None or status >= 400:
            dead_links.append((link, status))

    if dead_links:
        print("\n🚨 Dead links found:")
        for link, status in dead_links:
            print(f"❌ {link} (Status: {status})")
    else:
        print("\n✅ No dead links found!")

if __name__ == "__main__":
    main()
